{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reccurent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMk1SNiIS58phl1tiHWfKfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msh2481/CodeStyler/blob/main/Reccurent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1II5jRa_xi2"
      },
      "source": [
        "!rm -rf ./*\n",
        "!git clone https://github.com/msh2481/CodeStyler.git && mv CodeStyler/* . && rm -rf CodeStyler\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp_rIGE9DvEE"
      },
      "source": [
        "from random import shuffle, choices, choice\n",
        "from collections import deque, defaultdict, Counter\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWx9mjSMGS1w"
      },
      "source": [
        "CHUNK_SIZE = 6\n",
        "BATCH_SIZE = 256\n",
        "BATCHES_IN_TRAIN = 10\n",
        "BATCHES_IN_TEST = 2\n",
        "TRAIN_SIZE = BATCH_SIZE * BATCHES_IN_TRAIN\n",
        "TEST_SIZE = BATCH_SIZE * BATCHES_IN_TEST\n",
        "MIN_OCCURENCES = 10\n",
        "MEMORY = 400\n",
        "DEPTH = 2\n",
        "L1_WEIGHT = 1e-4"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMtsU1nro22g"
      },
      "source": [
        "def fmt(number):\n",
        "    return '{:.5f}'.format(number)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU9muuIWBcxJ",
        "outputId": "87fa5f3b-cbed-457c-ff4c-a6bbb8a7fb7a"
      },
      "source": [
        "rawTexts = []\n",
        "alphabet = Counter()\n",
        "for filename in open('filenames.txt'):\n",
        "    if len(rawTexts) > TRAIN_SIZE + TEST_SIZE:\n",
        "        break\n",
        "    text = open(filename.strip()).read()\n",
        "    if 'debug' in text or 'DEBUG' in text:\n",
        "        continue\n",
        "    alphabet.update(text)\n",
        "    for pos in range(0, len(text) - CHUNK_SIZE + 1):\n",
        "        rawTexts.append(text[pos : pos + CHUNK_SIZE])\n",
        "alphabetCount = Counter()\n",
        "alphabetCount['█'] = 0\n",
        "for x, y in alphabet.items():\n",
        "    if y >= MIN_OCCURENCES:\n",
        "        alphabetCount[x] += y\n",
        "    else:\n",
        "        alphabetCount['█'] += y\n",
        "alphabet = [x for x, y in alphabetCount.items()]\n",
        "ALPHABET_SIZE = len(alphabet)\n",
        "print(f'alphabet of length {len(alphabet)}: {alphabetCount}')\n",
        "\n",
        "shuffle(rawTexts)\n",
        "print(f'{len(rawTexts)} texts in total')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alphabet of length 50: Counter({'0': 1200, ' ': 468, '█': 133, '\\n': 125, '1': 121, 'e': 104, 'n': 96, 'A': 84, 'a': 84, 'l': 77, 'u': 69, 'y': 65, 'E': 57, 'c': 54, 't': 54, '(': 53, ')': 53, 'S': 52, 'v': 50, ':': 46, 'r': 44, '=': 39, 's': 36, 'f': 35, 'T': 34, 'b': 33, 'h': 32, '/': 30, 'i': 29, '\"': 27, 'N': 25, 'B': 25, 'L': 25, '{': 24, '}': 24, 'U': 21, 'p': 21, '_': 20, 'R': 19, 'C': 18, '>': 18, 'I': 17, 'g': 17, '-': 16, 'o': 16, 'k': 15, 'M': 14, '<': 14, 'W': 13, 'z': 11})\n",
            "3747 texts in total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4y1ZhRmUF3A"
      },
      "source": [
        "charToIndexMap = { c : i for i, c in enumerate(alphabet) }\n",
        "def charToIndex(c):\n",
        "    return torch.as_tensor(charToIndexMap.get(c, ALPHABET_SIZE - 1), dtype=torch.long)\n",
        "\n",
        "def stringToTensor(cur):\n",
        "    x = torch.zeros(size=(len(cur), ALPHABET_SIZE))\n",
        "    for j in range(len(cur)):\n",
        "        x[j][charToIndex(cur[j])] = 1\n",
        "    return x\n",
        "\n",
        "class StringDataset(Dataset):\n",
        "    def __init__(self, strings):\n",
        "        super(StringDataset, self).__init__()\n",
        "        self.strings = strings\n",
        "    def __len__(self):\n",
        "        return len(self.strings)\n",
        "    def __getitem__(self, i):\n",
        "        return stringToTensor(self.strings[i])\n",
        "\n",
        "trainSet = DataLoader(StringDataset(rawTexts[: TRAIN_SIZE]), batch_size=BATCH_SIZE, shuffle=True)\n",
        "testSet = DataLoader(StringDataset(rawTexts[TRAIN_SIZE : TRAIN_SIZE + TEST_SIZE]), batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oniJOQwuVuWw",
        "outputId": "601275d5-a59b-4394-b011-8b18456d846e"
      },
      "source": [
        "print(len(trainSet), len(testSet))\n",
        "print('---')\n",
        "# print(next(iter(trainSet)))\n",
        "print('---')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 2\n",
            "---\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l52z5m8oISM4"
      },
      "source": [
        "class Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Predictor, self).__init__()\n",
        "        self.linear1 = nn.Linear(ALPHABET_SIZE + MEMORY, ALPHABET_SIZE + MEMORY, dtype=torch.double, bias=False)\n",
        "        self.linear2 = nn.Linear(ALPHABET_SIZE + MEMORY, ALPHABET_SIZE + MEMORY, dtype=torch.double)\n",
        "        self.linear3 = nn.Linear(ALPHABET_SIZE + MEMORY, MEMORY, dtype=torch.double)\n",
        "        \n",
        "        self.batchNorm1 = nn.BatchNorm1d(ALPHABET_SIZE + MEMORY, dtype=torch.double)\n",
        "        self.bias2 = nn.Parameter(torch.rand(ALPHABET_SIZE + MEMORY, dtype=torch.double, requires_grad=True))\n",
        "        self.bias3 = nn.Parameter(torch.rand(MEMORY, dtype=torch.double, requires_grad=True))\n",
        "\n",
        "    def forward(self, state, answer):\n",
        "        assert state.shape[1:] == (MEMORY, )\n",
        "        if answer.shape[1:] != (ALPHABET_SIZE, ):\n",
        "            uprint(state.shape, answer.shape)\n",
        "        assert answer.shape[1:] == (ALPHABET_SIZE, )\n",
        "        inputTensor = torch.cat((state, answer), dim=1)\n",
        "\n",
        "        relevanceTensor = torch.sigmoid(self.linear3(inputTensor) + self.bias3)\n",
        "\n",
        "        inputTensor = torch.cat((torch.mul(state, relevanceTensor), answer), dim=1)\n",
        "        updateTensor = torch.sigmoid(self.linear2(inputTensor) + self.bias2)\n",
        "        deltaTensor = torch.relu(self.batchNorm1(self.linear1(inputTensor))) - inputTensor\n",
        "\n",
        "        resultTensor = inputTensor + torch.mul(updateTensor, deltaTensor)\n",
        "        state, answer = resultTensor[:, : MEMORY], resultTensor[:, MEMORY :]\n",
        "        return state, F.softmax(answer, dim=-1)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDr-qL-a8L5"
      },
      "source": [
        "lossFunction = nn.NLLLoss()\n",
        "\n",
        "def parametersTensor(predictor):\n",
        "    return torch.cat(tuple(elem.view(-1) for elem in predictor.parameters()))\n",
        "\n",
        "def gradientsTensor(predictor):\n",
        "    return torch.cat(tuple(elem.grad.view(-1) for elem in predictor.parameters()))\n",
        "\n",
        "X_ORT = None\n",
        "Y_ORT = None\n",
        "\n",
        "def tensorTo2D(v):\n",
        "    global X_ORT, Y_ORT\n",
        "    if X_ORT is None:\n",
        "        assert Y_ORT is None\n",
        "        X_ORT = torch.rand(v.shape, dtype=torch.double)\n",
        "        Y_ORT = torch.rand(v.shape, dtype=torch.double)\n",
        "        X_ORT = F.normalize(X_ORT, dim=0)\n",
        "        Y_ORT = F.normalize(Y_ORT, dim=0)\n",
        "    vx = torch.mul(v, X_ORT).sum()\n",
        "    vy = torch.mul(v, Y_ORT).sum()\n",
        "    return vx, vy\n",
        "\n",
        "def evaluateOnBatch(predictor, batch):\n",
        "    N = batch.shape[0]\n",
        "    batch = batch.permute(1, 0, 2)\n",
        "    assert batch.shape == (CHUNK_SIZE, N, ALPHABET_SIZE)\n",
        "    state = torch.rand((N, MEMORY), dtype=torch.double, requires_grad=True)\n",
        "    answer = torch.rand((N, ALPHABET_SIZE), dtype=torch.double, requires_grad=True)\n",
        "    loss = torch.tensor(0, dtype=torch.double)\n",
        "    accuracy = torch.tensor(0, dtype=torch.double)\n",
        "    for i in range(CHUNK_SIZE):\n",
        "        expected = batch[i].argmax(dim=-1)\n",
        "        assert expected.shape == (N, )\n",
        "        for it in range(DEPTH):\n",
        "            state, answer = predictor(state, answer)\n",
        "            assert state.shape == (N, MEMORY)\n",
        "            assert answer.shape == (N, ALPHABET_SIZE)\n",
        "            if i > CHUNK_SIZE // 2:\n",
        "                loss += lossFunction(answer.log(), expected)\n",
        "        if i > CHUNK_SIZE // 2:\n",
        "            accuracy += (answer.argmax(dim=-1) == expected).double().mean()\n",
        "        answer = batch[i]\n",
        "    return accuracy / (CHUNK_SIZE - CHUNK_SIZE // 2), loss / ((CHUNK_SIZE - CHUNK_SIZE // 2) * DEPTH)\n",
        "        \n",
        "def train(predictor, optimizer, startEpoch):\n",
        "    predictor.train()\n",
        "    trainAccuracy = 0\n",
        "    trainLogLoss = 0\n",
        "    trainSize = 0\n",
        "    for batch in islice(trainSet, BATCHES_IN_TRAIN):\n",
        "        optimizer.zero_grad()\n",
        "        accuracy, loss = evaluateOnBatch(predictor, batch)\n",
        "        loss = loss + parametersTensor(predictor).abs().sum() * L1_WEIGHT\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trainAccuracy += accuracy\n",
        "        trainLogLoss += loss.item()\n",
        "    trainAccuracy /= BATCHES_IN_TRAIN\n",
        "    trainLogLoss /= BATCHES_IN_TRAIN\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictor.eval()\n",
        "        testAccuracy = 0\n",
        "        testLogLoss = 0\n",
        "        testSize = 0\n",
        "        for batch in islice(testSet, BATCHES_IN_TEST):\n",
        "            accuracy, logLoss = evaluateOnBatch(predictor, batch)\n",
        "            testAccuracy += accuracy\n",
        "            testLogLoss += loss.item()\n",
        "        testAccuracy /= BATCHES_IN_TEST\n",
        "        testLogLoss /= BATCHES_IN_TEST\n",
        "\n",
        "        px, py = tensorTo2D(parametersTensor(predictor))\n",
        "        gx, gy = tensorTo2D(gradientsTensor(predictor))\n",
        "        print(f'State in 2D: parameters = ({px}, {py}) gradients = ({gx},  {gy})')\n",
        "        print(f'#{startEpoch}: {fmt(trainAccuracy)} {fmt(trainLogLoss)} {fmt(testAccuracy)} {fmt(testLogLoss)}')\n",
        "        print(flush=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXs0InGgwC37"
      },
      "source": [
        "def samplePrediction(predictor, length):\n",
        "    s = ''\n",
        "    sFull = ''\n",
        "    prefix = choice(rawTexts)\n",
        "    state = torch.rand((1, MEMORY), dtype=torch.double)\n",
        "    answer = torch.rand((1, ALPHABET_SIZE), dtype=torch.double)\n",
        "    for i in range(length):\n",
        "        for it in range(DEPTH):\n",
        "            state, answer = predictor(state, answer)\n",
        "            guess = answer[0].argmax(dim=-1).item()\n",
        "            sFull += alphabet[guess]\n",
        "        w = list(*answer.detach())\n",
        "        guess = choices(alphabet, w)[0]\n",
        "        if i < len(prefix):\n",
        "            guess = prefix[i]\n",
        "        answer = torch.zeros((1, ALPHABET_SIZE))\n",
        "        answer[0][charToIndex(guess)] = 1\n",
        "        sFull += '>' + guess\n",
        "        s += guess\n",
        "    print(f'=== {len(s)}, {len(sFull)} ===')\n",
        "    print(f's:{s}')\n",
        "    print(f'sFull:{sFull}')\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpBDZhhMwSx",
        "outputId": "51b69251-d86b-4188-9e40-2d9d013c90f1"
      },
      "source": [
        "predictor = Predictor()\n",
        "optimizer = torch.optim.Adam(predictor.parameters(), lr=0.001, weight_decay=1e-2)\n",
        "\n",
        "for i in range(10 ** 9):\n",
        "    train(predictor, optimizer, i)\n",
        "    print(i)\n",
        "    samplePrediction(predictor, 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State in 2D: parameters = (0.8511753020463649, 0.8430423526518136) gradients = (0.0072320406273229144,  0.007818484207550071)\n",
            "#0: 0.06497 3.87821 0.17383 3.68155\n",
            "\n",
            "0\n",
            "=== 64, 256 ===\n",
            "s: {\n",
            "   _B oWIRz)//// /// e</(g=M00a/rfgvlo000  iEoo( :0/  o  :0oo\n",
            "sFull:C:> To>{oo>\n",
            "on> {n> nn> _v>_vv>BvR> Re>oWr>WWW>ICC>R=0>z0i>)//>///>///>///>// > //>///>/:/>// > /e>e/<><o/>/r(>(ig>g =>=rr>M00>0:0>0██>a0/>/ r>rSf>f0g>g0v>vzl>loo>o 0>000>000>0  > █ >  █>i/E>Eho>o<o>o (>(( >  :>:00>00/>/a > o >  o>og >   > v:>:00>00o>o0o>o\n",
            "State in 2D: parameters = (0.7761603409114564, 0.7724468721833002) gradients = (0.008368081220900232,  0.00971411333789106)\n",
            "#1: 0.19935 3.51407 0.25521 3.39343\n",
            "\n",
            "1\n",
            "=== 64, 256 ===\n",
            "s:0000000Cyb\n",
            "=a>}<         oE  (Eo 00 {          //       o E0    \n",
            "sFull::S>0{T>000>000>000>000>000>000>C00>y00>b00>\n",
            "((>==(>aa(>>>/>}}/><  >   >   >   > / >   >   >   >   > █o>o E>E  >   > /(>(/E>E o>o  >  0>0 0>0█ > ██>{  >   >   >   >   >   >   >   > / >   >  />///>/0 > / >   >   >   >   >   >  o>o  >  E>E00>0  >   >   >   > \n",
            "State in 2D: parameters = (0.7493261127458134, 0.7485868270197028) gradients = (0.00796639999033148,  0.007164988553457045)\n",
            "#2: 0.25898 3.23114 0.24609 3.11746\n",
            "\n",
            "2\n",
            "=== 64, 256 ===\n",
            "s:STCASE/gWafr/Uaatze\n",
            "<yp\n",
            "zvrbbiA\"bSiWAiv)nR:UcsN}aI)u=R(v:1o1Trn1\n",
            "sFull:█ >SAh>TTo>CAA>AAA>SSc>EE<>/rb>ggb>Wb1>aAr>fru>rla>//<>U<<>aat>aa<>ttv>zv1>e11>\n",
            "1A><AA>yy>>p>A>\n",
            "\n",
            "l>zll>vuu>rne>bbe>bbr>iiy>AA<>\"\"v>bbv>Svv>ii1>W11>A11>i11>vv<>)<<>n<t>RR1>::1>UU1>c11>s1A>NN>>}}y>aa<>I<<>))v>uv1>=  >RR >(AA>vAA>:<<>1<<>o11>111>T11>r11>n11>1\n",
            "State in 2D: parameters = (0.7229570093936861, 0.7236720949573069) gradients = (-0.003925876935115229,  -0.003283464131273463)\n",
            "#3: 0.27708 2.98582 0.28320 2.87965\n",
            "\n",
            "3\n",
            "=== 64, 256 ===\n",
            "s:000000=(_M nnnnnn   n\n",
            "  \n",
            "11\n",
            "S1nS y 1n  l1 l ln 1l yylll1     S 1\n",
            "sFull:█r>0nn>0)R>000>000>000>000>=00>(uu>_u\n",
            ">MM\n",
            "> \n",
            "n>nnn>nnn>nnn>nnn>nnn>nn >   >   >  n>n1\n",
            ">\n",
            "1 >   >  \n",
            ">\n",
            "n1>111>11\n",
            ">\n",
            "\n",
            "S>S 1>1Sn>n S>Sl > 1y>y1 > y1>11n>n  > n >  l>l11>1y > nl>ly > ll>lln>nl > l1>1ll>l  >  y>yyy>yll>lll>lll>l 1>1\n",
            " >   > 1 > l >   > 1S>S1 >  1>1\n",
            "State in 2D: parameters = (0.701981310872575, 0.7014979804859822) gradients = (-0.00041487012550942514,  0.0017820845250265023)\n",
            "#4: 0.30000 2.76581 0.31576 2.65440\n",
            "\n",
            "4\n",
            "=== 64, 256 ===\n",
            "s:       █z\"b:\"}=e<:\n",
            "=  t}=cy/E:/0nNy)btWRNt}\n",
            "L=-z00AIcagb-oTk:1M)\n",
            "sFull:█ >   >   >   > ff> u >   >   >█ c>zcc>\"c >bcc>:ee>\"))>}))>=yy>eyy><yy>:AA>\n",
            "ll>=  >   >   >t c>}cc>=c >cco>ype>/))>E))>:)S>/SS>0(y>nyy>Nyy>yyA>)Sh>bh >tye>Wee>R  >Nel>tt(>}((>\n",
            "\n",
            " >L/ >=  >-ce>z((>0o)>0)y>A00>I00>cla>aal>guu>bee>-ll>oAe>Tep>krl>:)p>1p1>M11>)\n",
            "State in 2D: parameters = (0.6424586267951824, 0.6440021329244526) gradients = (0.02800311481776772,  0.028348297016587774)\n",
            "#5: 0.33646 2.55576 0.37695 2.43149\n",
            "\n",
            "5\n",
            "=== 64, 256 ===\n",
            "s:un cas\"iB<oI\n",
            "I/IL)h\n",
            ">e\"hovcbp )p=c(csryr<L<\"b\n",
            "ny)p>ovIsc<p_Le\n",
            "o{\n",
            "sFull:█h>uAE>n(y> AA>caa>asl>suu>\"e)>i\n",
            "\n",
            ">B\n",
            "l><<n>onn>IyA>\n",
            "//>I//>///>Iyy>Lye>))\n",
            ">hhl>\n",
            "\n",
            " >>//>ecp>\"py>hee>opp>vyo>cll>bep>pee> p >) \n",
            ">pln>=\n",
            "e>cee>(ep>cpp>see>re\n",
            ">ypp>ree><op>L\n",
            "\n",
            "><yn>\"ne>bep>\n",
            "yp>n//>ypp>))e>phi>>pp>opo>voo>Ill>sse>ce\n",
            "><yA>ppp>_yo>L(e>eee>\n",
            "\n",
            "\n",
            ">o//>{\n"
          ]
        }
      ]
    }
  ]
}