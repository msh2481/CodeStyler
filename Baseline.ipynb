{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2OQqG6yTbrK/45nl+joBp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msh2481/CodeStyler/blob/main/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1II5jRa_xi2",
        "outputId": "9d3d3776-366d-48e7-bf5e-08ef3f5dcf89"
      },
      "source": [
        "!rm -rf ./*\n",
        "!git clone https://github.com/msh2481/CodeStyler.git && mv CodeStyler/* . && rm -rf CodeStyler\n",
        "!ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CodeStyler'...\n",
            "remote: Enumerating objects: 7921, done.\u001b[K\n",
            "remote: Counting objects: 100% (7921/7921), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6521/6521), done.\u001b[K\n",
            "remote: Total 7921 (delta 1399), reused 7918 (delta 1399), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7921/7921), 9.07 MiB | 16.27 MiB/s, done.\n",
            "Resolving deltas: 100% (1399/1399), done.\n",
            "filenames.txt  files  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp_rIGE9DvEE"
      },
      "source": [
        "from random import shuffle\n",
        "from collections import deque, defaultdict, Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from nn import functional as F"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWx9mjSMGS1w"
      },
      "source": [
        "TARGET_TEXT_SIZE = 2 ** 8\n",
        "ALPHABET_SIZE = 256"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU9muuIWBcxJ"
      },
      "source": [
        "rawTexts = []\n",
        "for filename in open('filenames.txt'):\n",
        "    text = open(filename.strip()).read()\n",
        "    parts = len(text) // TARGET_TEXT_SIZE + 1\n",
        "    partLen = len(text) // parts\n",
        "    for pos in range(0, len(text), partLen):\n",
        "        rawTexts.append(text[pos : pos + partLen])\n",
        "alphabet = sorted(list(set([ch for text in rawTexts for ch in text])))\n",
        "assert len(alphabet) < ALPHABET_SIZE"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1wnMkQCDmTR",
        "outputId": "cf5cae2e-0fda-465e-e167-a600d01ca2c8"
      },
      "source": [
        "print(f'alphabet of length {len(alphabet)}: {alphabet}')\n",
        "shuffle(rawTexts)\n",
        "print(f'{len(rawTexts)} texts in total')\n",
        "print(rawTexts[:10])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alphabet of length 244: ['\\x00', '\\x02', '\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', 'Â§', 'Â©', 'Â«', 'Â®', 'Â±', 'Â²', 'Âµ', 'Â·', 'Â»', 'Â¿', 'Ã„', 'Ã…', 'Ã–', 'Ãœ', 'ÃŸ', 'Ã¤', 'Ã¥', 'Ã¶', 'Ã¼', 'Ä°', 'Ä±', 'Å‰', 'Å¿', 'Æ»', 'Ç„', 'Ç…', 'Ç†', 'Ç‡', 'Çˆ', 'Ç‰', 'ÇŠ', 'Ç‹', 'ÇŒ', 'Ç±', 'Ç²', 'Ç³', 'Ê°', 'Ê¼', 'Í…', 'Î’', 'Î•', 'Î˜', 'Î™', 'Îš', 'Îœ', 'Î ', 'Î¡', 'Î£', 'Î¦', 'Î©', 'Î²', 'Îµ', 'Î¸', 'Î¹', 'Îº', 'Î¼', 'Ï€', 'Ï', 'Ï‚', 'Ïƒ', 'Ï†', 'Ï‰', 'Ï', 'Ï‘', 'Ï•', 'Ï–', 'Ï°', 'Ï±', 'Ï´', 'Ïµ', 'Ðš', 'ÐŸ', 'Ð°', 'Ð±', 'Ð²', 'Ð³', 'Ð´', 'Ðµ', 'Ð¶', 'Ð·', 'Ð¸', 'Ð¹', 'Ðº', 'Ð»', 'Ð¼', 'Ð½', 'Ð¾', 'Ð¿', 'Ñ€', 'Ñ', 'Ñ‚', 'Ñƒ', 'Ñ„', 'Ñ…', 'Ñ†', 'Ñ‡', 'Ñˆ', 'Ñ‰', 'ÑŠ', 'Ñ‹', 'ÑŒ', 'Ñ', 'ÑŽ', 'Ñ', 'Ñ‘', 'Ù ', 'Ù¡', 'Ù¢', 'Ù£', 'Ù¤', 'Ù¥', 'Ù¦', 'Ù§', 'Ù¨', 'Ù©', 'á¹ ', 'á¹¡', 'áº›', 'á¾¾', 'â€“', 'â€”', 'â€¦', 'â„–', 'â„¦', 'â„ª', 'â„«', 'â… ', 'âˆ†', 'â”€', 'â”‚', 'â”Œ', 'â”', 'â””', 'â”˜', 'â”œ', 'â”¤', 'â”¬', 'â”´', 'â”¼', 'æ–¤', 'ï¬€', 'ï¬ƒ', 'ï¿½', 'ðŸ˜ƒ']\n",
            "162286 texts in total\n",
            "['ameters += createSynthesizedValueParameter(0, \"name\", context.irBuiltIns.stringType)\\n            loweredConstructor.valueParameters += createSynthesizedValueParameter(1, \"ordinal\", context.irBuiltIns.intType)\\n            loweredConstructor.valueParameter', 'l nullableNothingType = context.session.builtinTypes.nullableNothingType.coneType\\n        for (varargParameter in varargParameters) {\\n            val varargParameterType = varargParameter.returnTypeRef.coneType.arrayElementType() ?: continue\\n        ', '//.filter { devirtualizationAnalysisResult.instantiatingClasses.contains(it) }\\n                        val actualCallee = when (call) {\\n                            is DataFlowIR.Node.VtableCall ->\\n                                receiverType.vtable[c', '// WITH_RUNTIME\\nimport kotlin.test.*\\n\\nclass ComparablePair<T : Comparable<T>>(val first: T, val second: T) : Comparable<ComparablePair<T>> {\\n    override fun compareTo(other: ComparablePair<T>): Int {\\n        val result = first.compareTo(other.first)\\n', 'etbrains.kotlin.fir.analysis.diagnostics.reportOn\\nimport org.jetbrains.kotlin.fir.declarations.*\\nimport org.jetbrains.kotlin.fir.resolve.diagnostics.ConeCyclicTypeBound\\nimport org.jetbrains.kotlin.fir.symbols.impl.FirTypeParameterSymbol\\nimport org', \"f NEW uninitialized value was saved to local at least once\\n * 2. If it wasn't then do nothing\\n * 3. If it was then:\\n *   - remove all relevant NEW/DUP/LOAD/STORE instructions\\n *   - spill rest of constructor arguments to new local vars\\n *   - generate NEW\", 'mbol): Boolean =\\n        analysisSession.symbolDeclarationOverridesProvider.isSubClassOf(this, superClass)\\n\\n    public fun KtClassOrObjectSymbol.isDirectSubClassOf(superClass: KtClassOrObjectSymbol): Boolean =\\n        analysisSession.symbolDeclara', 'RFACE) {\\n                return kotlinClassFinder.findKotlinClass(\\n                    container.classId.createNestedClassId(Name.identifier(JvmAbi.DEFAULT_IMPLS_CLASS_NAME))\\n                )\\n            }\\n            if (isConst && container is ProtoCo', 'omic1\\n        atomic2.value = Holder2(atomic1, atomic2).freeze()\\n        atomic3.value = Holder2(atomic3, atomic1).freeze()\\n        val cycles = GC.detectCycles()!!\\n        assertEquals(3, cycles.size)\\n        assertArrayEquals(arrayOf(atomic3, atom', 'alueArgument(0, expression.value.toIrConst(signedType))\\n\\n            return callStack.pushInstruction(CompoundInstruction(constructorCall))\\n        }\\n        callStack.pushState(expression.toPrimitive())\\n    }\\n\\n    private fun interpretReturn(expression: ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4y1ZhRmUF3A"
      },
      "source": [
        "charToIndexMap = { c : i for i, c in enumerate(alphabet) }\n",
        "def charToIndex(c):\n",
        "    return charToIndexMap.get(c, ALPHABET_SIZE - 1)\n",
        "\n",
        "dataset = [np.array(list(map(charToIndex, text)), dtype=np.uint8) for text in rawTexts]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oniJOQwuVuWw",
        "outputId": "ff2534e6-4bb4-4a25-f229-aea5e06dec4d"
      },
      "source": [
        "print(dataset[0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(254,)\n",
            "[69 81 73 88 73 86 87  4 15 33  4 71 86 73 69 88 73 55 93 82 88 76 73 87\n",
            " 77 94 73 72 58 69 80 89 73 52 69 86 69 81 73 88 73 86 12 20 16  4  6 82\n",
            " 69 81 73  6 16  4 71 83 82 88 73 92 88 18 77 86 38 89 77 80 88 45 82 87\n",
            " 18 87 88 86 77 82 75 56 93 84 73 13  3  4  4  4  4  4  4  4  4  4  4  4\n",
            "  4 80 83 91 73 86 73 72 39 83 82 87 88 86 89 71 88 83 86 18 90 69 80 89\n",
            " 73 52 69 86 69 81 73 88 73 86 87  4 15 33  4 71 86 73 69 88 73 55 93 82\n",
            " 88 76 73 87 77 94 73 72 58 69 80 89 73 52 69 86 69 81 73 88 73 86 12 21\n",
            " 16  4  6 83 86 72 77 82 69 80  6 16  4 71 83 82 88 73 92 88 18 77 86 38\n",
            " 89 77 80 88 45 82 87 18 77 82 88 56 93 84 73 13  3  4  4  4  4  4  4  4\n",
            "  4  4  4  4  4 80 83 91 73 86 73 72 39 83 82 87 88 86 89 71 88 83 86 18\n",
            " 90 69 80 89 73 52 69 86 69 81 73 88 73 86]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l52z5m8oISM4"
      },
      "source": [
        "class Predictor:\n",
        "    def __init__(self, SUFFIX_SIZE):\n",
        "        self.SUFFIX_SIZE = SUFFIX_SIZE\n",
        "        self.suffixToWeights = torch.ParameterDict()\n",
        "        self.suffix = deque()\n",
        "    \n",
        "    def startNewText():\n",
        "        self.suffix = deque()\n",
        "\n",
        "    def probabilityOfNext(self, number):\n",
        "        if self.suffix not in self.suffixToCounts:\n",
        "            self.suffixToCounts[self.suffix] = torch.rand(ALPHABET_SIZE, dtype=torch.float)\n",
        "        weights = self.suffixToCounts[self.suffix]\n",
        "        probabilites = F.softmax\n",
        "        total = counter.total()\n",
        "        if not total:\n",
        "            print('It always ended after this suffix...')\n",
        "            return 0\n",
        "        return counter[number] / total\n",
        "\n",
        "    def addToSuffix(self, number):\n",
        "        self.suffix.append_right(number)\n",
        "        if len(suffix) > self.SUFFIX_SIZE:\n",
        "            self.suffix.pop_left()\n",
        "    \n",
        "    def guessNext(self):\n",
        "        counter = self.suffixToCounts[self.suffix]\n",
        "        total = counter.total()\n",
        "        if not total:\n",
        "            print('No data to base guess on')\n",
        "            return 0\n",
        "        return counter.most_common(1)[0]\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDr-qL-a8L5"
      },
      "source": [
        "def train(predictor, )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}